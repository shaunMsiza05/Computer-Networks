So what is the internet? It's an international computer network that interconnects billions of computing devices. In traditional terms, the internet connects PCs and  servers, but because of an evolution in technology, the internet now interconnects nontraditional devices like wearables and even fridges! (thanks to the internet, hackers can now access your diet). From this perspective, we can explain computer networks on the basis of this huge example. All these interconnected devices are called ednd systems or hosts and are interconnected by many communication links.

Communications link differ in their hardware, which means they also differ in the speed with which they trasmit data (the speed is measured in bits per second). They can come as optical fiber, copper wires or coxial cables. But the data being tranfered my be segmented and formated in a specific manner before it is transferred. In computer jargon, this segmented piece of data is called a packet. 

To summmaries what we have learned so far, a computer network is a system that connects many end sytems which share data in the form of packets transfered through communication links. But how does a packet now where to go? If we have a simplistic network with only two computers, that would't be a problem. But because a computer network is made up of many communication links that link an end system to more than one destination, a third component is required. A packet switch. This component takes a packet from an incoming link and transfers/switches it to its destined link. Therefore what makes this componen important is because data isn't transfered on a linear path but on a network of intersecting links. Two examples of packet switches are routers and link-layer switches.

//I like this way of revising, you learn something and rewrite it in your own words. But for now, let me outline the book.


The internet
- two approaches to defining it.

The nuts and bolts
- end systems
- two components that connect end systems
- examples of the media of communicating links (radio spectrum for wireless).
- transmission rate
- packets
- packet switches (routers (core) and link-layer switches (access network), respective use cases).
- network path/router
- the analogy of a truck network
- ISPs (different types), defintion, and protocol.
- why should ISPs be interconnected
- hierachy of ISPs
- examples of uper-tier ISPs
- components of an upper-tier link
- protocols (two examples).
- the importance of protocols and standardisation
- internet standards (developer IETF)
- RFCS, the protocols they define.

As an infrastructure for distributed applications
- definition of distributed applications
- the purpose of a socket interface 
- communication without protocols
- congestion control protocols
- the http protocols

The edge of networks
- the approach
- two categories of hosts
- data centres

the access network
- brief definition
- approach
-two common broadband residental acesss: digital subscriber line (DSL) and cable
- who provides DSL

DSL
- the function of a DSL modem
- the function of a DSLAM
- the different channels of a DSL
-the function of a splitter
- the dsl standards
- when are these standards at met
- factors that impact the DSl's transmission rates

CIA
- the parallel between DSL and cable acess
- the components of the infrastructure
- a cable modem and its function
- the function of a CMTS
- its channels
- downstream for receiving packects
- upstream for sending packets (corresponding protocol).
- HCF

FTTH 
- direct fiber
- two splitting network archictectures: AOP and PON.
- the function of a splitter
- it's link to a OLT
- how users connect to a ONT
- transmition rate	
- the satellite link and its importance
- dial-up access and its disapointing speed.
// I have to do 100 pages per day. Fucken robotic

Ethernet
- typical setting: LANs
- the function of an ethernet switch, speed
- wireless LAN an technology used: IEEE 802.11
- how access points are connected
- base station

Physical media
- three types
-guided vs unguided

Twisted pair
- cost
- composition
- reason for twisting

Coxial cable
- composition
- as a shared medium

Fiber options
- how it transmits
- speed
- electromagnetic interfence
- use in overseas links

Radio spectrum

Terrestrial radio channels
-defining characteristics
- limiting factors: shadow fading, multipath fading, and inteference.
- classifications

Satellite radio channels
- ground stations, their functions
- two types and respective features
- propagation delay

The network core

Packet switching
- packets
- packet switches: routers and link-layer switches
- the formula  for the time it takes to trasmission
- store-and-forward transmission
- buffering
- an example of transmitting four packets
- formula for number of routers for N-links
- end-to-end delay formula, logic behind it
- output buffer
- output queing and the subsequent concept of quieng delay
- main factor that influences queing delay: congestion
- what leads to packet loss

Packet forwarding in the internet
-IP  adresses and their function to the router
- forwarding tablets
- how are forward tables set
- an example of a routing protocol in forwarding tables.

Circuit switching
-main feature
- telephone networks as an example
- how a transmission rate is reserved
- dedicated end-to-end connection
- divion of transmission capacity
- circuit switching contrasted with it counterpart
- frequency-division multiplexing
-bandwidth
- Time-division multiplexing
- it's transmission rate (frames rates times bits in a slot)
- disadvantages of circuit switches
- silent periods
- complexity
- two examples that explain why packet switching is more efficient
- packet switching is more efficent based on the propability of active users

The internet
- interconnected ISPs

pseudo structures of the internet
- Network Structure 1 - directly connected ISPs
- global ISP transit

Network Structure 2 - competing global ISP transit
 - regional ISPs
 - tier-1 ISPs, examples

-Network Structure 3 - multi-tier hierarchy

-Network Structure 4
- POPs, multi-home, peering, and IXPs

-Network Structure 5 - content service providers

Packet-Switched Network
- total nodal delay and its elements:
- queuing,  nodal processing, propagation, and transmission delay.
- traffic intensity and its correlation to packect losss
- how trace route programs work
- media packetization
- packetization delay

 Throughput 
- instantaneous throughput
- average throughput
- bottleneck link
-

Protocol layering
- definition and interesting analogy
- two basic models

Application layer
- service
- 4 protocols and their respective functions
- packet term

Transport layer
- service
- protocols: UDP and TCP, which is superior
- packet term

Network layer
- service 
- protocol: IP
- routing protocols: OSPF

Link layer
-service
- protocol: DOCSIS, Ethernet, and IEEE802.11
- node-to-node transmition and the varaibility of services

Physical layer
- service
-protocol dependence
- are these layers followed similary in the case of wireless LANs
threats to a network
- botnet
- Dos and three types
- solution of packet sniffing
- IP spoofing and solution


Chapter 2 - Application layer
- two predominant application architectures

- client-server
- unique identifier for server
- examples of network applications using this: Telnt, email, and web
- virtual servers

- P2P
- key difference
- hybrid architectures
- risk factors 
- comparison of the 2 in terms of scalability

Process communicating
- OP's as governing interprocess
- how client and server are distinguished in the context of processes
- two steps of addressing
- port number

Sockets (APIs)
- purpose
- relation to transport protocol

Transport protocol
- four main services to apllications

reliable data transfer
- two main causes of packet loss
- use case
- loss-tolerant applications

Throughput
- use case
- band-width sensitivity
- dynamic throughput allocation
- elastic applications and examples

Timing
- use case and examples

security
- services

TCP/UDP

TCP
- services
- how a tcp connection is established
- data reliablity
- full-duplex
- Secure sockets layer, services, data encryption, intergrity, and end-point authentication.

UDP
- constrast to TCP
- services provided by the internet in relation to the four aforementioned

Application layer protocols
- purpose
- public domain vs proprietary
- distiction from applications

HTTP
- the effect of www in the 90s
- its application architecture
- its RFCs (1945, 2616)
- base html file
- web objects
- the two components of a url
- role of browsers
- examples of server, Apache and Microsoft Internet Information Server
- hyperlink clicks as requests
- underlying protocol
- as a stateless protocol
- how http server respond to multiple requests
- persistent vs nonpersistent connections
- pipelining, as default mode (http 1.1)
- configurable timeout inerval

HTTP messages
- for request messages
-request line and its fields
- headerlines
- three fields of request line: the get method, url, and version
- content negotiation headers
- head method for debugging

cookies (RFC 6265)
- two reasons to identify users
- elements: header lines in either message, cookie on user sytem browser managed, back-end database.
- generation of IDs
- set cookie header
- cookie

web caching
- proxy server
- process
- what it stores
- use by ISPs
- best case scenario with proxy servers
- benefits: reduced traffic on access link, and quick response time
- user session layer
- a comparison of installing a web cache and improving the access link
- CDNs
- conditional caches
- status line: 304 not modified

Electronic Mail

- most popular 1998
- asychronous communication medium
- features: attachments, hyperlinks, html-formatted text, and embedded photos.
system
- user agents, mail servers and SMTP
- user agents allow user to read, save, forward, and reply
- outgoing message queue
- mail boxes as components of mail servers
- authentication by mail server
- reattempts of sending messages
- use of TCP
- acting as both client and server
- 7-bit ASCII restriction
- port 25
- application-layer handshaking
- SMTP commands: Mail From, RCPT TO, DATA, and QUIT
- what SMTP commands really do

Mail access protocols
- host based architecture
- 1990s implementation of server-client
- reason against host-based servers
- two-step producedure

SMTP
- RFC defined 5321
- original dates 1982
- intermediate servers
- port number 25
- persistent connections
- ISP

SMTP VS HTTP
- pull vs push protocol
- ASCI restriction
- how messages are rendered

SMTP header
- header lines
- optinal header lines

Access protocols
- end users as mail servers

POP3
- RFC 1939
- PORT 110
- three phases: authorisation, transactions, and update
- transactions: retrieving, marking and unmarking for deletion, and update
- quit
- +OK, ERR
- commands: list , retr , dele , and quit
- authorization commands: user and pass
- difference between download-and-keep, and download-and-delete
- state information

IMAP
- RFC 3501
- remote servers
- state information accross sessions
- Inbox folder
- parts of messages

Web-based email
- hot mail
- use in both sending and retrieving

DNS
- context-based identifiers
- types of internet identifiers: hostnames and ip addresses
- hostnames routers
- ip addresses as hierarchical

Services of DNS
- application architecture
- how it differs from other applications
- main service
- database design
- transport protocol
- port 53
- software: BIND
- OS: Unix
- protocols that use it
- an example of its process
- reverse dns query
- dns delay and means of its mitigation

Other services
- host aliasing: canonical hostname, dns invoking

mail server aliasing
- mnemonics for mail servers
- use of identical aliases through mx records

Local distribution
- replicated servers
- mapping of one canonical name to multiple ip addresses
- RFC - 1034 and 1035

Hirerchical servers
- three classes
- dns lookup process

Dynamic DNS
- static vs dynamic address
- update time
- processes: canonical names

Root servers
- number of managing organisations and distribution

TLD servers
- common domains
- server clusters
- educause
- verisign

Authoritative servers
- company owned
- provided by service providers
- backup servers

Local DNS servers
- ISPs
- default name servers
- DHCP
- range from host
- as proxies
- intermediate servers
- iterative vs recursive queries

DNS caching
- caches by local host
- discarding records
- bypassing root servers

DNS records
- resource records
- field

Types of records
- A
- NS records
- Cname
- MX records
- configuring common alises using mx and Cname records
- RRs for authoritative servers
- RRs for other dns servers

DNS messages
- two types
- `12 btyes header, fields: id, flags, num of questions, answer RRs, authority RRs, and additional RRs

Sections
- question: name and type
- answer: value, type, ttl. Multiple RRs
- authority: identify other authoritative servers
- additional: example

Adding dns records
- registra
- two inserted records (Additional)

DNS security
- Ddos
- 2002 attack
- bypassing root servers

Peer-to-peer file distribution
- architecture
- most popular protocol (2026)

Bit torrent
- torrent 
- chunks
- tracker
- minimum num for torrents
- list of chunks of neighbouring peers
- rarest first
- trading algorithm (tit-for-tat)
- unchoked peers
- optimistically chocked peers
- mechanisms: pieces, pipelining, random first selection, endgame mode, and anti-snubbing.
- DHT

Video streaming and CDNs
- companies that provide streaming
- streaming process
- video in cs terms
- pixels
- parameter for better video quality
- bit rate for low-quality and high-definition content
- average-throughput and its relation to bit rate
- use of compression to create multiple versions of the same video

HTTP streaming and dash
- retrival process
- client appplication buffer
- streaming as a function of frame buffering and receiving

DASH
-its purpose
- chunks corresponding to bit rate
- significance to mobile users
- manifest files
- rate determination algorithm and implementation

CDNs
- three main problems of a single data centre, geographic distance, cost-effectiveness, and spof
- how cdns solve this problem
- private vs third party cdns

server placement philosophies
- enter deep and relation to ISPs
- bring home and relation to IXP
- disadvantage of bring home
- cluster-specific demand
- how caches unload

Cluster selection strategies
- proprietary strategies
- geographically closest
- disavantages of the above strategy
- real-time measurements strategy
- drawback

Netflix
- traffic in 2015
- four services
- its inception and cdn infrastructure
- netflix's own cdn deployment
- rack selection strategy

Kankan

Transport layer
- the function of this layer with respect to the network layer.
- two fundamental problems in networking, with respect to reliable communication and congestion control

Transport-Layer Services
- as a medium for logical communication
- with respect to network routers
- fragmentation to form segments
- how the network layer treats packets on the receiving end

Relationship between the transport-Layer and network-layer
- distinctions in the service provided
- an interesting analogy
- the contrainsts caused by the network-layer protocol

Transport layer for the internet
- two options
- terminology for udp packets
- the service offered by the ip protocol
- transport layer multiplexing and demultiplexing
- the two main services offered by UDP

Multiplexing and demultiplexing
- the responsibility of the transport layer protocol on the receiving end
- the use of unique identifiers for sockets
- demultiplexing as pushing segments to appropriate sockets
- how correspondent sockets are identified through fields
- multiplexing as fragmentation and passing segments to the network layer protocol
- format, size, and range of port numbers
- well-known port numbers
- automatic port number generation on the client side and statically on the server side
- reason to identify the source port number

connection-oriented multiplexing and demultiplexing
- format of socket identifier
- assigning port numbers to well-known application

Port scanning
- identifying which applications are running on a host by scanning for open ports
- typically used by system administrators to identify network applications running on hosts on their network
- use by attackers to case the joint
- Slammer worm
- nmap for udp and tcp ports

Web servers and TCP
- use of threading to create multiple subprocesses on one process

Connectionless transport: UDP
- the basic requirements of a transport-layer protocol
- works with four fields
- performs some light error checking
- rfc 768
- dns as an application that uses udp
- reasons to use udp:
   - finer control on what data is sent and when, for example, real-time can tolerate some loss, require a minimum transmission rate, and don't want long delays from TCP's retransmission
   - no connection established: establishing connections before transfer may be undesireable for delay-sensitive applications like UDP. Http's slow download is cause by TCP. The chrome browser implemented QUIC, which implements reliability at the application layer and runs udp
- no connection state: parameters used for connection are ack and seq numbers, sender and receiver buffers, and congestion-control parameters, whithout this waste, udp servers can support more users
- small packet overhead: tcp segment has 20 byte header overhead, udp 8.
- UDP's effect of no congestion-control on the network
- the four fields in detail (all 2 bytes): checksum, length (payload and header), source and destination 

UDP checksum
- the formula for the checksum: performing the 1s complement sum of all 16-bit words in the segment
- perfoming checksum on this layer instead of choosing lower layer to perform it.
- the end-to-end principle in system design

Principles of reliable data transfer
- as a general subject in networking
- tcp's role to provide a reliable channel for data tranfer
- the complexity of building reliability on top of an unreliable transfer mediumq

Developing a reliable data transfer protocol
- assume the underlying channel can lose or corrupt bits
- one method of the sender side is rdt_send(), called by upper layer protocols to send data
- methods on the receiving end: rdt_rcv() called when a packet is received, deleiver_data() called when the data has to be passed to the upper layer.
- more requirements: sending and receiving control packets using udt_send() and udt_rcv(), and bidirectional reliable data transfer (full-duplex mode)

rdt 1.0
- the first version, with fsms defined for the sender and receiver
- the finite-state machine of the sender:
    - event: rdt_send()
    - actions: packet = make_pkt(data), udt_send(packet
- the finite-sate machine of the receiver:
    - event: rdt_rcv(packet)
    - actions: extract(packet,data), deliver_data(data)
- limitations: a reliably perfect channel is assumed
              - no congestion-control implemented

rdt 2.0
- let's assume data corruption for a more realistic design
- data corruption is typically caused by physical components of a networks as packets are buffered, transmitted, or propagated.
- a real life analogy of a mechanism to navigated data corruption: "Got you" positive acknowledgement, and "what did you say to me" a negative ackowledgement
- automatic repeat request protocols as based on retransmisions
- three functions perfomed by ARQ protocols:
   - error detection: implementing a mechanism to detect bit errors on the receiving end so that they can be corrected using auxiliary fields
   - receiver feedback: the recepient sending feedback when data is received correctly and when it isn't using two 1-bit packets: ACK (1) and NaK (0)
   - retransmission: resending a packet that arrived corrupted at the recepient
   - the finite-state machine of the sender:
     - event: rdt_send()
     - action: sndpkt = make_pkt(NAK), udt_send(sndpkt)
     - after these stage, another boolean-based even is intitated: rdt_rcv(rcvpkt) && isACK(rcvpkt)
- when the sender is in the above state, data can not be received from the upper layer protocol
    - the finite-state machine of the receiver:
      - event: rdt_rcv(rcvpkt) && isNAK(rcvpkt)
- stop-and-wait protocols
- one flaw of this design: no way of handling corrupted NAk and Ack packets. 
- three possibilites:
   - implementing more checksums and feeback, leadong to a rabbithole
   - allowing the sender enough bits to solve the checksum
   - the sender resending the packet upon receiving garbled ack or nak packets: this is not reliable because the reciever cannot tell appart new data packets from retransmissions
-one solution is to implement sequence numbers, which allow the protocol to distinguish new data packets from retransmissions
- we wont add sequence numbers to ACks or Naks, since we are assuming a channel with zero packet loss

Reliable data transfer over a channel that may lose packets rdt 3.0
- two concerns: how to detect a packet loss and how to recover from it
- two possibilities for no feeback to the user: a lost sender packet or lost acknowledgement
- the issues involved in determining a timer for retransimision
- the maximum delay for retransmission as a function of the round-trip delay and transmission and propragation delays
- the difficulty of estimation the maximum delay for retransmission
- choosing an arbitrary interval to wait as a last resort
- duplicate packet may arise if retrasmission is triggered before packet return
- our previous design uses sequence numbers to handle duplicates
- use of a countdown timer to gauge interval for retransmission
- the countdown timer should start each time a packet is sent, respond to a timer interrupt (dont understand what that means), annd stop the timer
- additionally, the protocol should measure how many retransmissions can be done to a single receiver in a given session, otherwise, it will be stuck retransmitting to an inactive user. interestingly, this can be used as an attack on the protocol, scan for ports, find someone running this protocol, initiate a handshake but don't acknowledge it, keeps the receiver retransmitting, or just a request but turn inactive when its time to receive the response
- summary of neccessary elements of a reliable data transfer protocol: sequence numbers, checksums, countdown timers, and positive and negative acknowledgements

Pipeline protocol vs stop-and-wait
- come back to outline the math
- this mechanism allows the sender to send mutliple packet without waiting for acknowledgements
- requirements brought by pipelining on reliable data transfer protocols:
   - longer sequence numbers, using just 0 and 1 can only work in a stop-and-wait scenario
   - since retransmission is sometimes neccessary, more than one unacknowledged packet will have to be buffered, specifically those waiting for retransmission
  
Pipelining error handling
Go back N
- base range is the function of the base (sequence number of the oldest unacknowledged packet), and the next sequence number, basically the sequence of the packet next inn line
- four intervals are computed from this base range:
- interval 2: the range of sequence numbers that have been sent and ackowledged, formula (0, base -1)
- interval 2: the range of sequence numbers that have been sent but unackwoledged , formuala (base, seqNum - 1)
- interval 3: the range of sequence numbers that can be used fro packets from the upper layer protocol: (seqNum, base+N-1)
- interval 4: the range which cannot be used until unacknowledged packes have been returned, not neccessarilty all unacknowledged packets, even 1. formula, greater than or equal to base + N
- the window size is the range of permissible unacknowledged packets
- as unacknowleged packets are acknowledged, the window size shifts, which is why this protocol is called a sliding window protocol
- congestion control as one reason to limit the number of unacknowledged packets
- extended FSM for rdt 3.0, includes variables base and nextSequenceNumber, and a few conditionals

3 types of events for the GBN sender:
- the sender can be invoked from the upper-layer protocol, however, the conditional is that the method is executed only if the window is not full
- the timer method is still included, set only if there are unacknowledged packets, tracks the ack of the oldest transmited but unacknowledged packet, timer reset everytime an unACKEd packet it received, unless it is the last unreceived
- the feeback mechanism is still used, with an extension for a cumulative acknowledgement number N, signifying all unacknowledged packets up to N have been acked
- the receiver still perfoms the normal functions of received data and sending ACKs or NAks, in terms if cumulative acknowledgment, if k is acked, then k - 1 packets are acked
- cumulative acknowledgement as a natural choice for GBN
- the reciever need not buffer out of order packets since they will be retrannsmited anyway

Selective receiver
- allows the sender to only retransmit only those packets which are suspected to be in error
- this reuqires the receiver to individually acknowledge packets

Conection-oriented transport: TCP
- preliminary handshakiing before data transfer
- as a full duplex service
- as a point-to-point mechanism
- the exchange of three control packets during handshake
- the first two packets have no payloads, the third may contain a payload
- the use of a send buffer set aside during the handshake
- the maximum segment size which determines the size of data carried in a tcp segment
- the MSS is set by determining the length of the largest link-layer frame, based on the MTU
- the typical size of MSS is 1460 bytes, based on an MTU of 1500
- the MSS is specifically the maximum size of the payload
- the data on the receiving end is stored in a receive buffer
- in short, a tcp consists of variables, buffer, and a socket connection
 
TCP segment structure
- consists of both header fields and a data field
- tcp header size typically 20 bytes
- telnet as an interaction application that may transmit one-btye data fields
- last segments as typically containinng data less than the MSS

TCP header
- 32 bits for both source and destination port numbers used for multiplexing and demultiplexing
- a 32 bit sequence number and a 32 bit acknowledgement number, both use to implement reliable data transfer
- the 16 bit receive window is used for flow control. and highlights the amount of data the receiver can take
- 4 bytes header length field: due to the options field, the tcp header is of a variable length, the length is represented in 32-bit words
- the variable length options field is used in mss negotiation and in scaling the receive window for high speed networks
- the 6 byte flag field:
- ACK -self explanatory
- SYN, FIN, and RST are used for connection set up and teardown
- PSH - the receiver should pass the data to the upper layer immediately
- URG - used to specify data that the sending side upper layer deems as urgent. urgent data pointer field (16 bytes) indicates the last byte od the urgent data

Sequence numbers and acknowledgement numbers
- tcp views data as an unordered stream of bytes
- the sequence numbers are set on the btye-stream, as opposed to the transmitted segments
- the number in the sequence number field is the sequence number of the first byte in the data field
- the acknowledgement number
- to me, its a request like mechanism
- used to highlight the sequence number of the first byte in the next byte-stream expected from the sender
- also used to request a missing byte-stream when two btye-streams are received from the sender, but there's a gap in their sequence number, which will disrupts packet reassembly. 
- tcp acknowledges bytes up to the first missing byte, a process called a cumulative acknowledgement.
- tcp buffers out of order packets on the recieved instead of discarding and hoping for retransmissions
- initial sequence numbers are chosen randomly to avoid conflicts with packets that may get returned from already terminated previous packets
- tcp sequence numbers are exhanged during the handshaking process, to simplify the requests of initial packet, presumably

Telnet, in the context of tcp
- rfc 854
- telnet is an interactive application, meaning it doesnt send bulky data
- typically sends a one-btye stream for each character, which is echoed back to the client for display
- data is ASCII formatted
- piggybacked, the ack of one packet appears as a sq for the returned packet

Round-trip time estimation and timeout
- use of a smaple RTT, this is not computed for all segements but is interval-based
- sampleRTT - the time measured for when a segment is sent and its ack is received
- sampleRTTs are not computed for retransmitted packet
- the sampleRTT will fluctuate for every segment for which it is computed
- estimatedRTT - an average maintained on the fluctuation sameRTT values
- devRTT - measures how much the sampleRTT varies from the estimatedRTT
- the timeout interval should be based on the estimatedRTT with some margin
- the margin for the timeout interval should be large when there's lot of fluctuation and vice versa
- the initial timeout interval is 1 second
- when a timeout occurs on the above value, the value is doubled

Reliable data transfer
- on unreliable IP, packets may arrive out of order, corrupted, and even lost during transit
- use of a single-timer for retransimission
- main events: receiving data from upper layer, timer timeout, and ACK
- sendBase holds the sequence number of the oldest unacknowledged packet
- if a received ack's sequence number is greater than sendBase, then that's a cummulative ack and requires updating the sendBase

Interesting scenarios
- retransmission trap from lost ACKs and discarded retransmissions
- retransmission withheld because of an ack of a later packet is received without the ack of the packet that precedes and accompaniees

Principles of congestion control
- main cause of packet loss as overflowing buffers
- mechanisms needed to throttle sender upon network congestion

Scenario 1: two senders segmented by a router with infinite buffers
-a transport layer that doesnt provide error recovery is assumed
- so packets are buffered when the packet arrival rate exceeds the outgoing link's capacity
- because two connects are assummed, the link capacity for each is R/2
- or a sending rate within the designated rate, the throughput at the receiver the sender's sending rate
- when the sending rate of either device exceeeds R/2, then the links capacity becomes its throughput and cannot exceed it
- as the sending rate grows larger than R/2, the delay, assuming an unbounded buffer, reaches infinity
- the average delay on the sender will near infinity as more and more transmitted packets are queued


- here's an interesting possibility, can someone, like a malicious isp, create a router that makes copies of all packets passing through it for exploitation. has any employee ever done such a thing. To make the question more fruitful, have isp ever been accussed or 
caught in an act of large scale sniffing. 


Scenario 2: two senders and an intermediate router with finite buffers
- finite buffers result in packet loss
- assuming a transport layer protocol that retransmits packets
- offered load is the rate at which the sender sends data and retransmissions
- two unrealistic assumptions:
- packet retransmissions occur only if the sender is assured that packets are lost (this can be done based on an exceedingly high timeout interval
- the sender only sends data when the intermediate router's buffers are empty
- another cost of congestion is that of packet loss 
- another cost of congestion is unneccessary retransmissions triggered by large delays
- empty or not full, quite unlikely to find an empty buffer
- anoter cost of congestion, when a packet is dropped along a path, the transmission capacity used by the intermediate hops is wasted,capacity which would have been beteer utilised for different packets

Scenario 3: four senders, routers with finite buffers, and multihop paths
- you probably mismatched the outlines, but read on and fix that
two approaches to congestion control based on whether the network layer provides support to the upper layer:
- end-to-end congestion control: 
  - approach taken by TCP
  - tcp segment loss is used as an indicator of congestion,and TCP modifies the window size accordingly
- network-assisted congestion control:
   - routers send notification about the traffic conditions
- two forms of notification: the router sends a choke packet, a field is maintained to carry the notification

TCP congestion control
- the congestion mechanism is perceived as opposed to network-assisted
- three main concerns: what algorithm to use to measure congestion, how to determine if there's any congestion, and lastly, how to throttle the sender
- the congestion window variable - it imposes a contrainst on the rate at which the sender can transmit data into the network
- how the send rate is dynamically adjusted
- loss event as the timeout depletion or receipt of three duplicate acks
- loss events as indicators of congestion
- acks are signal of a congestion free network and are used to adjust the congestion window size accordingly
- bandwith probing - frequently and dynamically adjusting the send rate based on the perceived
- tcp as self-clocking - using predetrmined events to adjust the window size
- the complexity involved in adjusting the rate, mainly, ensuring that the rate is set at a level that doesn't underutilise the available badwidth
- three guiding principles followed to adjust the sender's sending rate:
    - lost segments as indicators of congestion 
    - received acks signify a congestion-free network, thus the window size can be increased
- the effect of low bandwidth links on the adjustment of cwnd
- general formula for send rate equals cwnd/rtt

TCP congestion control algorithm
- includes, slow start, congestion avoidance, and fast recovery
- slow start as faster thab comgestion avoidance
- fast recovery as recommended by not mandatory

Slow start
- cwnd is intialised as 1 MSS
- intial send rate set at 1MSS/RTT
- every time an acknowledgement is received, cwnd is doubled by one MSS
- cwnd is restarted to 1mss when a loss event occurs
- ssthresh stores half the value of the highest cwnd before a loss event is triggered
- since its illogical to keep doubling the cwnd after the ssthresh has been reached, tcp enters the congestion avoidance mode

Congestion avoidance
- initial state is half cwnd
- the rate of increases cwnd is by adding 1mss for every rtt
- reacts similarly to slow start
- slow events may be timeout interval timeout or the receipt if three duplicate acks
- tcp reacts differently to a three-duplicate-ACKs based loss event
- cwnd is half and three MSS are added
- ssthresh is haved as expected
- then a loss event in this state triggers the fast recovery state (which was said to be optional)

Fst recove

The network layer
- two parts: data and control plane
- data plane is responsible for forwarding datagrams from input to output links
- the control plane - coordinated per packet forwading actions
- routing - the process of computing the path t a destination
- use of routing protocols running in the forwarding plane to populate forwading tables
- inability to respond to network convergement and being error-prone as two disadvantages of human configured routing table
- forwading tables sent by an SDN controller
- remote SDN controllers as being controlled by third-party organisations and ISPS

Network layer service model
- guranteed delivery - packets are guranteed to reach the destination
- delivery with bounded delay - packets are guranteed to reach the destinatio within a specified interval
- minimal bandwith - a specific sending rate is offered to the sender 
- security - data is encrypted and decrypted
- the IP protocol as a best service protocol
- the interchangeable use of the term switching with forwarding
Routers
- four components:
   - data plane (hardware)- input and output ports, and switch fabric
   - control plane (software) - routing process
- output ports: received packets from switch frabric in order to send to outgoing link. can be paired with an output port to support bidirectional communication
- switching fabric - connects input to output ports
- routing processor - communicates wih sdn controller in sdn architecture, used in network management, computes forwarding tables and executes routing protocols
- input ports - terminal incoming links, perfoms forwarding lookups

Priority queuing
- arriving packets are assigned priority classes
- for example, prioritising nms packets. nms packets can be ided with source/destination port, even dest addresses if your nms is a dedicated
- each class has its own queue
- read in FIFO style
- non-preemptive priority queuing means packet in transit cannot be disrupted

Round robin and weighted fair queuing 
- this alternates service among classes
- so alternating from one class with available packets to another
- work-conserving queuing - the link cannot be id;e due to priority considered while packets are available
- so in conclusion, the link scheduler will alternate to another class irregardless of the queue in the preceding class

weighted fair queing
- also a work conserving queuing mechanism
- similar to round robin 
- classes may recieve a differential amount of service in any interval of time



- that this imply that each priority class has its own buffer, we can containise various buffers over the same buffer


- simulate the use of rtt to determine servers that are nearest








IP: IPv4 and IPv6 and addressing
IPv4 datagram format
- version
- header length - neccessitated by the variable length of the header due to options
- TOS: can separate datagrams of different types. for example packets of real time applications and their counterparts
- datagram length: header plus payload. 16 bit field, making the maximum header lrngth 65 535
- but the above is typically set at 1500 due to MSS
- fragmentation: identification, flags, and fragment offset
- ttl
- protocol: determines the transport layer that should process the packet at the receiving end
- protocol number as analogous to port number
- the protocol number ties the transport layer to the network layer
- the port number ties the application layer to the transport layer
- header checksum - checks performed on the header of the datagram
- performs 1s complement sum on th 16 bit words in the header
- the field has to be recomputed since the ttl and options field may change
- so the checksum cannot be standardised since the transport layer is not constrained to ip, and ip is not constrained to UDP/TCP
- source and destination addresses: sender inserts its address to the datagram and looks up the destination address using dns. 
- options - used to extended the header. separated from the header in oder to cut overhead
- data (payload) - carries tcp/udp segmnents. may also carry empty payloads and icmp messages

IPv4 datagram fragmentation
- variable mtus offered by layer 2 protocols
- 1500 as a standard of ethernet
- 576 bytes for wan links
- the contrainst of the MTU on the ip datagram
- the three requirements for fragmentation: identifying the last fragment to start reassembly and to determine the relative position of the fragment. tp also determine datagrams that are fragments
- the variation in MTU for different link layer protocols
- fragment as a concept arising from a router tasked with a datagram that exceed the outgoing link's MTU
- fragments of the same datagram have similar id, source, and destination address
- reassembly as a responsibility of the hosts as opposed to routers
- set the MF flag to 0 for last fragment

Ipv4 addressing
- addresses are tied to hosts
- 4 possible addresses
- formatted in dotted decimal notation
- a subnet as a combination of a gateway and host interfaces
- institutions are address network prefixed from which they derive contiguous subnets
- cider as a alternative to classful addressing
- the way in which foreign prefixes are treated by routers

Principles in action
- route summarisation, route aggregation and route aggregation as a process by which a router advertises a single address divisible into multiple subnets using cider
- the subnet address

Obtaining address blocks for organisational use
- begins with network admin contacting ISP, I guess this is done when also leasing the ISP link
-  Internet corporation for assignedd names and numbers as the organisation that manages the allocation of address blocks to ISPs
- ICANN also manages dns root servers
- also assigns domain names and resolves disputes
- reginal address block assignmnet is done by internet register organisation which together form part of the address domain of ICANN

DHCP
- as an automatic alternative to static address assigned
- as an option suited to mobile users
- as a good option for address utilisation as address a leased temporarily
- also assigning default gateway, subnet masks, and dns server
- use of dhcp relay agents on subnets without a dedicated dhcp server
- client can renew lease 
- downside with lack of mobility is that tcp connections cannot be persisted accross subnets
- adopts a C/S architecture
- as a plug-and-play solutions
- four steps involved:
   - the newly connected host broadcasts a dhcp discover packet onto the network with source address 0.0.0.0 and destination address 255.255.255.255. it's a udp packet on port 67
- all dhcp servers respond with an offer, sends a reponse at port 67
- the offer also includes lease duration, network mask, and the address itself
- the request is an echo for the chosen offer
- last packet, an ACK by the server confirming parameters





for a sec, i thought offers where broadcasted frequently but they are initiated by the discover packets

NAT 
- the unfeasible case of assigning address segments to SOHO
- private addresing and its relation to NAT
- NAT-enabled routers being perceived as a single device in the public network
- NAT addresses are obtained from dhcp servers of ISPs
- use of port numbers and translation tables to distinguish various internal hosts
- because the size of the source port is 16 bit, the wan interface address can support over 60 000 simultaneous connections
- the complications brought by NAT's use of port numbers
- nat can minimise the proability of interfering with other services in its use of port numbers by avoiding well known port numbers
- two port related domains affected by NAT: FTP applications and port operations of weel known applications
- NAT traverslal and universal plug and play as solutions to port related NAT complications
- network layer middleboxes

Focus on security
- attackers may map your topology, scan ports, crash devices with malformed packets, and send malware
- two popular defense devices: firewalls and intrusion detection systems
- IDS used for deep packet inspection
- IDs mantain a signature database of common attacks
- database is updated to accomodate new attacks
- intrusion prevention systems also block packets, in addition to creating alerts



IPv6
- the main purpose for the development of this protocol
- 2011 as the last time IANA allocated an address block to an internet regitster
- ipv5 term was reserved for ST-2
- higher address space, which can assign address to all grains of the sand on the planet
- anycast address, and its use in load  balancing
- fixed-length 40 bytes header and extension headers for options
- flow-labeling - labeling flows. definition unclear. May be refering to real time applications as flows

Fields in IPv6 datagram
- only note those which are unique to ipv6
- traffic class - TOS equivalent - used to assign priority to datagrams
- payload length - identifies the length of a payload, 16 bits
- next header - identifies the upper layer protocol
- hop limit - ttl equivalent
- data - carries the payload
- source and destination address - self-explanatory

IPv4 vs IPv6 datagram format
- fragmentation and reassembly fields like ID,  fragment offset, and flags
 - by moving fragmentation to end systems, less processing is done by routers
- when router receives a packet greater than outgoing mtu, it discards and sends an icmp notification
- header checksum removed because lower transport layer and link layer protocols checksum entire packet
- removal of options field for a fixed length 40 byte header, options are added as extension headers

Transition from IPv4 to IPv6
- lack of forward compatibility of current IPv4 legacy systems
- flag day on which the IPv4 will be dropped and its unfeasibility
- using of tunneling, which involved encapsulating ipv6 datagrams on ipv4 datagrams to routing on intermediate ipv4 systems
- the evident complexity of a widespread adoption of new network layer protocols

Routing algorithms
- role as to compute good path between endpoints
- good path as a subjective parameter
- edge cost and its various determinants
- main goal of routing algorithms as determining the least-cost path
- the least cost path of mutliple equal cost paths is the shortest path
- the shortest path is the path with the smallest intermediate links
- centralised routing algorithms:
  - aware of the entire network
  - can be replicated accross routers or performed by a single central controller
  - typically called link-state algorithms
- decentralised forwading:
  - no node has global information of the network
  - each node only has info of directly connected links in initial state
  - the least-cost path is calculates through an iterative process of information wxhange
  - example of this implementation is the distance-vector algorithm
  - each node maintains a vector of estimates
- further classification:
   - dynamic - respond to network convergence immediately
   - static - responds to network convergence slower, typically due to network convergence
- third classification: load-sensitive - cost vary dynamically to represent traffic conditions. And load-insensitive - uncommon because of complexities involved

Link-state routing algorithm
- input - network topology and link costs
- node periodically broacast link state infomration - containing costs and identities
of directly connected links
- use of a link-state broadcast algorithm by OSPF
- discussed example is Dijkstra’s algorithm, related to Prim
- Dijkstra’s algorithm as iterative - output - after k iterations, the least-cost paths of k nodes are known, and then computed least-cost paths will have the k smallest cost
- executed based on a loop, number of loops equal number of nodes
- worst-case complexity of the algorithm: d: O(n ). 
- costs are not asymmetric

The distance vector algorithm
- its a distributed algorithm
- each node receives information from directly attached neighbours to perform calculations and distributes the computations to the directly connected neighbours
- it is iterative in that it stops when no information has exchanged anymore
- it is self-terminating inn that it can stop without receiving a specific signal
- distance-vector estimates are updated when a cost change is detected or when a neighbour sends a distance-vector update
- it is decentralised in that no node stores global information
- the only infomarion maintained are the costs of the link connecting to neighbours and information sent by neighbours
- function a node can perform:
   - awaits neighbour distance vectors, recomputes its own distance vectors based on estimates, and distributes distance vectors to neighbours
- protocols based on DV: RIP, BGP, ISO IDRP, NOVELL IPX, and ARPANET
- the process goes on till no updates are sent, in which case it enteres the quiescent state

Distance vector algorithm: Adding poisoned reverse
- used as a counter measure againnst a looping problem

Link state vs distance vector algorithm
- In DV routing, the neighbour sends least cost paths estimates to directly connected neighbours about all the noded it knows of
- In LS routing, the node broadcast information to all other nodes in the network

Message complexity:
- DV algorithm - messages are excanged between directly connected neighbours for each iteration
- changes result will only be propagated it the cost affects the a node's least-cost path

Speed of convergence
- DV connverges slowly
- DV suffers from the count-to-infinity problem
- DV can also suffer loops during convergence
- LS requires O(N, E) messages
- the LS algorithm tis an O(N)2 algorithm


Robustness
- the population of the routing table is donne independently for each node
- an incorrect packet will poison the entire network under DV

Intra-AS routing: OSPF
- reasons why it is unfeasible for routers to run the same routing algorithm:
   - scale: 
     - it is unsound for an internet router to maintain routing information about all possible destinations in the network. Not only in terms of storage but also computation capacity
   - administrative autonomy: 
        - network operators desire to run their own network in ways suitable to their enviroment, making a centralised routing algorithm a contrainst
- both problems are solved through autonomous systems, which are a group of routing protocl runnig the same routing protocol and under the same administrative control

Open shortest path first
- related to IS-IS
- open is meant to highlight the protocol specifications being available in the public domain
- example of closed source intra-AS algorithm: Cisco EIGRP 
- specifications of Cisco EIGRP have only been released after 20 years
- link costs are configured by admin
- so a broadcast algorithm is used to flood link state information
- least cost paths are then computed using Dijkstra’s algorithm
- the protocol has a mechanism to check for operational links
- the protocol also allows routers to obtain a neighbouring router's database
- packets are broadcasted to respond to network topology changes
- the protocols also checks if liks are operational
- also performs period broadcasts even when no convergence is detected
- must also perform eliable message transfer and link-state broadcast

OSPF link weights
- reflect the cost of using a link
- if weights are set to be inversely proportional to capacity, then the weight of high capacity will be smaller, making their preference higher
- the link weights may be modified by the network admin as a way to engineer traffic

highlights of OSPF
- security: 
   - packets exchanged between routers can be authenticated
   - only trusted OSPF routers can join an autonomus system
   - non-authentication is the default of state
   - the are two modes: simple and MD5
   - in simple authentication, the password is preconfigured on all the routers
   - the password is appended to all packets exchanged
   - insecure because packets are sent in plaintext
   - in MD5, the hash function is perfomed on every packet
   - the resulting hash value, secret key, and data packets are sent to the receiver, presumably
   - the receiver will use the secret key to perform the MD5 hashing on the packet and compare the resulting hash value with the sent value
   - sequence values are also used to protect against replay attacks
- support for hirearchy within a single AS:
    - each area run its own instance of ospf
    - broadcasts of one area are limited to that area only 
    - each area has one or more border routers for inter area communication
    - so all inter-area communication goes through the backbone area
    - one one backbone area can exisst in an autonomous system
    - all border routers connect to the backbone area
 
Routing among ISPs: BGP
- an inter-autonomous routing protocol is used to route packets between autonomous sytems
- for multiple As to be coordinated, they must run the same inter-AS routing protocol
- the standard protocol for inter-AS routing is BGP
- its an asynchronous and decentralsed distance-vector protocol
- for routing tables: destinations within the AS are determined by the intra-SA protocol
- in BGP, packets are routed to network prefixes
- an inter-AS protocl provides the following mechanisms:
  - BGP allows ASs to advertise their subnets to the rest of the internet
  - allows the best route to be a prefix to be determined using a policy and reachability information

Advertising BGP route information
- a gateway router is on the border of an AS and connects to routers of other ASs
- an internal router is a router that connects only to nodes within the same AS
- each router in an AS running BGP learnt both about the existence of a prefix and the path or paths leading to it
- BGP routers exchange routing information semi-permanent TCP connections 
- the conections use port 179
- an external BGP is a BGP connection spans two (or more?) autonomous systems.
- an internal BGP is a connection between routers in the same automous system
- the gateway router distributes the network prefixes to the internal routers using iBGP connections
- a route is a network prefix with its corresponding attributes
- the AS-PATH contains a list of paths passed by an advertisement
- when a prefix passes an AS, the AS adds its ASN to the AS-PATH
- the AS-PATH attribute is also used to prevent looping advertisements
- when a router detects its ASN in an AS-PATH of an advertisement, it discards it
- the NEXT HOP is the lefmost interface of the first AS in the AS-PATH list
- three main componnents of a BGP route: network prefix, AS-PATH, and NEXT-HOP

Hot Potato Routing
- the route with the least-cost is the route with the smallest number of links transversed
- the forwading table is then consulted to find the interface that correspond to the least-cost path
- then an entry is then made to the forwarding table
- the above process uses both the inter and intra-AS rotuting protocols of the AS

Route selection algorithm
- BGP uses an algorithm more complex than hot potato
- the best route is selected from all routes learned by the protocol
- if there's only one route, then the route will be selected by default
- otherwise, the step below are the elimination process:
   - each route has a local preference attribute which may be set by the router or learned from another router
   - this attribute is a policy decision that depends on the network admin
   - the route with the highest local preference is selected
2. the AS paths of the remaining routes are compared, the route whose AS Path list has a lower number of ASs is chosen.
- if this was the first step, BGP would be using a DV algorithm for path determination
3. if the above two steps dont return one route, then the hot potato routing is used. 
4. if one route doesnt remain still, BGP identifiers are used

IP-anycast 
- BGP is often used to implement this service
- so A CDN network may assign the same ip anycast address to each of its servers
- then BGP may be run to advertise the paths to each of these servers
- when a BGP router recieves the multiple advertisements, its treats them as multiple paths to the same location and performs the neccessary process to determine the shortest path
- the route selection-algorithms selects the best route based on hops
- ip any-cast is typically used by dns systems to direct queries to the closest root dns
- the ip any-cast is not widely adopted because a change in BGP may cause packets of the same TCP connection to be distributed across multiple web servers

Routing policy
- multi-homed access ISPs as access ISPs that connect to multiple backbone provider networks
- the use of BGP to control the flow of traffic for multi-homed access ISPs
- the rule of thumb for commercial ISPS: only traffic with either the source/destination addresses of networks served by the provider can pass through the network

Putting it all together
- compasny requirements:
   - a dns, email, and web server. 
   - internet connectivity by contacting your local ISP
   - your gateway router may have a direct link to the ISP router
   - there are various access soultions: DSL, fiber to the home, dial-up acess (is that tehe term), and cable access
   - the ISP will also provide a subnet, typically with a 24 bit mask
   - obtain a domain name for your company from a registrar
   - your company must also obtain presence in the dns system
   - push dns records that map hostnames of your servers
   - for your subnet to be internet reachable, it should be advertised to the internet
   - the routing protocol that performs the above function is BGP

The SDN control plane
- the SDN architecture:
  - flow based forwarding - forwarding is based on any number of header on any or all of the layers
  - separation of the data and control plane - 
     - data plane consists of the network's swicthes, which perfom the match plus action based on the flow table entries
     - control plane computes, manages, and installs flow tables entries in all of the switches
- network control functions: external to data plane switches: 
   - the software executes on servers that are remote from the switches
   - two components of the control plane: SDN controller and a set of network control applications
   - the control is distributed accross servers
   - the controller is logically centralised
- a programmable network:
   - programmable through the network control applications
   - use the API provided by the SDN controller to control the data plane of controlled devices
- the SDN approach unbundles network functionality, specifically the data plane switches, the control plane, and network-control applications

The SDN controller
- Comunication between the controller and controlled devices:
  - a protocol is neccessary to carry-out the above communication
- the devices must have preconfigured events whichh provide stateful information to the applications
- this type of communication is refered to as the southbound interface
- Openflow is the most common southbound protocol
- a network-wide state-management layer:
   - the control decisions made by the controller - including tewaking flow table configurations to achieve ends like load balancing and so forth requires the controller to have up to date stateful information about the controlled device.
- communication between the controller and the network-control applications:
   - this communication is done through the northbound interface
   - applications can be configured to be notified when state-change events occur
- so SDN is logically centralised
- multiple probe devices are used for fault talerance, high availablity, and for perfomance reasons

Openflow protocol
- southbound API
- runs on TCP 6653
- messages flowing from the controller to the controlled devices:
  - configuration: used by the controller to query or set a configuration
  - modify-state: used to add/delete or modify entries in a switch's flow table
  - read-state: used to collect statistics and counter values from the switch's flow table
  - send-packet: the message is used by the controller to send a specific packet out of a specified port of a controlled switch
- messages flowing from the controlled devices to the controller:
   - flow-removed - sent to notify the controller of a removed entry in a flow table
   - port status - used to signal a change in port status
   - packet-in - used to send packets that match no entry in the flow table (or matching a condition with an action sending them back to the controller) to the controller.


Google's software-defined global network
- google maintains a private wan to interconnect its data centres and server clusters
-  the network is called B4
- the networks has a Google-designed SDN control plane built on Openflow
- Google has a long term 70% 	WAN link utilisation
- applications are split between multiple links/paths based on application priority and existing flow demands
- data flows between applications are higher than those directed to users
- reasons google's B4 is well suited for SDN:
   - controls edge servers and routers in the network core
   - the bandwidth-intensive data transfers can be paused to allow more urgent interactive applications
   - centralised control is done on a few data centre
- each open flow agent connects to an open flow controller
- the open flow controller runs on a network control server
- the OFC is he southbound interface equivalent of the NCS
- the OFC perfoms state management functions
- the stateful information is kept in a network information base
- google's implementation of the OFC is based on the ONIX SDN controller
- B4 uses custom switches catered to google's needs
- each switch runs an openFlow agent
- two routing protocols are used, BGP as inter-AS and IS-IS as the intra-AS
- a traffic engineering network control application sits logically above the set of network control servers

the SDN control plane
- 

do the outline tommorow


- i was about to say what if the port connection the device to the controller is down, but my question is dumb, the messages are sent out the network and the switches, be it a layer 2 switch or a router, has link redundancy


- why would you want to send a packet out of a specified port of a controlled switch



- what's holding me from writing my own SDN protocol. I will run  it on my own onion routing implementation. So to revise, in onion routing we have routers that make up the tor service, are they servers or routers, I need to clarify that, but regardless, i can build them as servers and perform the neccary encryption


- I can already imagine this splitting of applications over the links. Google servers dynamic content from its mega data centre, let's assume a case in which google has to send youtube vs maybe google play downloads, which might google consider to be of a higher priority, my guess is the youtube content, at least that'a what I would have configured if I ran their network. I dont even know what google play is, wtf, that's play store and stuff. So google play is a platform for third party application, so I dont see why that should have a higher priority than google's own youtube. But youtube is also platform for third party content creators. To summarise the argument, google can push more ads on youtube than playstore, so it's better to prioritise the contents for the ads. 




- philosophical writing, as defined by Hall, is about making deductions about the most essential. I feel like this style has a place even in technical fields, especially IT. In IT, we come across various essential concepts through different stacks, liek the concept of load balancing and OSPF. I would be more interestsing if someone could write about this concepts in the abstract first before someone arives to them through a specifc stack. I dont have to learnt about redundancy by discovering it through network design, though that is more effecient. I can dive into the concept into itself before I dive into it any stack, in short, I am crying out for some technical platonic forms if you catch my drift











Openflow protocol
- southbound API
- TCP port 6653

The open daylight controller
-









ONOS controller
- three layers:
    - northbound abstractions and protocols:
       - a northbound interface provides the network-control application in two modes: 
         - synchronously (information can be queried)
         - asynchronously - 
    - distributed core:
         - the core is runs on a distributed server architecture, offering higher capacity
         - the server should run the same copy of ONOS
         - ONOs provides mechanisms for service replica and coordination among instances
         - the above logically centralises the core services
    - southbound abstractions and protocols: 
        - the southbound abstraction masks the heterogeneity of the underlying hosts, protocols, links, and switches
        - the above allows the core to be device and protocol agnostic

 what are listener callbacks?

Internet control protocol
- defined in RFC 792
- used for error reporting
- the payloads are carried in IP datagrams
- the receiving host demultiplexes to ICM using the protocol field in the datagram (set to 1)
- two main fields are used to distinguish different messages: code and type
- the ping program uses the echo request and reply of the protocol
- the ping server runs directly on the OS and is therefore not a process
- the ICMP source quench message is intented for congestion control but is rarely used
- traceroute uses ICMP payloads
- the traceroute increments TTL fields for each intermediate router
- a timer is set for each datagram sent
- the standard traceroute program sends a set of three packets to each intermediate router
- the traceroute program uses an uncommon UDP port
- each intermediate router returns ip address and timestamp to the traceroute client
- the destination device returns the port unreachable error (type 3 code 3) to the traceroute client
- the traceroute client should be able to instruct the OS to generate UDP packets with different TTL values
- the traceroute client should be able to receive ICMP messages from the OS
- a new version for IPv6 is defined in RFC 4443, for use in IPv6
- adds more messages like packet too big (IPv6 doesn't fragment by default) and unrecognised IPv6 options

Network management and SNMP
- simple network management protocol
- used by network admins to manage a complex network
- typical pre-SDN solution

Network management framework
- managing server:
  - an application running in a centralised nms in the network operations centre
  - it controls the collection, processing, analysis, and display of network management information
- managed device:
  - a network equipment in a managed network
  - contains managed objects
  - examples of the above: NIC and configuration parameters
- management information base:
   - the info can be queried and set by the managing server
  - the collection of managed objects
  - managed objects contains different types of information
  - the example of the above are OS versions of certain application servers and stateful information
  - structure of management information is used to specify MIB objects
  - the above language ensures syntax and semantic consistency
  - related objects are gathered into MIB modules
- each managed device runs a network management agent to communicate with the managing server
- this procedure is undertaken through a network management protocol
- agents can highlight exceptional cases to the managing server

SNMP
- version 2 defined in RFC 3416
- application-layer protocol
- use for request-response mode
- use for unsolicited messgaes
- PDU types:
   - get request, get next request and get bulk request
   - set request and inform request
   - response
- SNMP PDU format (four main categories):
   - get/set header, get/set variable, trap header, and trap information
- get set request receives a "no error" response
- the server is not expected to respond to a trap message
- well-known traps are defined in RFC 3418
- UDP is the prefered transport layer protocol, rfc 3417
- request ID field is used to sequence requests
- retransmissions are not mandatory
- SNMPv3 as concerned with security and more administration capabilities

The link layer and LANs
- two types of link layer channels
- examples of broadcast channels: wireless LANs, satellite networks, and fiber-coaxial cable access networks
- medium access protocols are used to coordinate frames for broadcast communication channel networks
- the other type is point-to-point communication link
- 

Intro to the link layer
- nodes as devices running a layer to protocol
- links as communication channels between adjacent nodes

Services provided by the link layer:
- framing: encapsulates datagrams into frames. The frame contains a data field and header fields
- link access: The MAC protocol specifies the rules by which a frame is transmitted on the link.
- the above is simpler for point-to-point links and more complex for broadcast access links
- reliable delivery:
   - used mostly but link access scenarios with high error rates. Minimises overhead by correcting errors locally as opposed to so doing in the end-to-end transmission path
- error detection and correction:
    - the bits in the frame may be corrupted by factors like EMI
    - to correct bit errors, frames are transmitted with error-detection bits
    - error correction differs in that the receiving end can determine the error and fix it
    - at this layer, error detection is more complex and is implemented in hardware
   
Link layer implementation
- on a router, it is done on the line card
- on a host device, it is done on the NIC or network adapter
- the brains of the NIC is the link-layer controller
- the services performed by the link-layer controller are link access, framing, and error detection etc
- LAN-on motherboard configuration - integration NICs onto motherboards
- the software components of the link-layer are responsible for higher functions like assembling link-layer addressing information and activating the controller hardware

Error detection and correction techniques
- so the sender sends both a frame and error detection and correction bits
- the receive may not detect all bit errors
- more accurate error detection techniques incur a large overhead

Parity checks
- the are two schemes: odd and even 
- a single parity bit may not suffice for cases in which errors occur in bursts
- the two dimensional parity scheme organises the bits into columns and rows
- since a bit error can be resolve to its specific location in the aforesaid scheme, error correction can be done
- forward error correction is the ability to detect and correct errors
- the above mechanism can help reduce the number of transmissions required

Checksumming methods
- data is treated as k-bit integers
- error-detection bits are obtained by summing the k-bit integers
- the internet checksum:
   - performs one's complement sum on 16 bit integers
   - the receiver takes the one's complement sum of the received data, including the checksum
   - if the result computed by the receiver is all ones, then no bit error occurred
   - TCP and UDP performs checksum on the entire packet
   - checksumming requires little overhead
   - tcp and udp use 16 bits
   - the transport layer is implemented in the host's OS
   - at the link layer, error detection is implemented in hardware, hence the use of the complex CRC operations
   
Cyclic redundancy check
- so this topic is a lil involved, so come back to give it an outline

Multiple access links and protocols
- the are two access links: broadcast and point-to-point
- multiple access problem: delas with coordinates the access of multiple sending and receiving nodes
- broadcast channels are used in LANs
- traditional broadcasting is used by television. It is unidirectional
- multiple access protocols are used to regulate the transmissions of nodes in a broadcast channel
- multiple network setting requiring the above protocol: satellite networks, wireless networks, and shared wire (like cable access)
- since multiple nodes can transmit at once, the broadcasted packets can collide at receivers
- the frames that collided are unintelligible to the receiver
- three classes of multiple access protocols: random access, channel partitioning, and taking-turns protocols
- desirable of multiple access protocols:
   - when a single node is active, it should utilise the entire throughput of the channel
   - when multiple nodes are active, the desirable throughput for each should be (total throughput)/ number of active nodes
   - 

Channel partitioning protocols
- two partitioning techniques: time-division and frequency division multiplexing

TDM
- time division multiplexing
- diving time into frames - time frames
- time frames are divide into N slots
- there's a distinction between frames and time frames
- each time slot is assigned to each of the N nodes
- slot times are set such that a single frame can fit into the slot
- a sending node can only transmit during its allotted time frame in the revolving TDM frame
- advantages: eliminates collisions and evenly distributes bandwidth
- disadvantages: 
    - a node should await its allocated slot even if it's the only node active
    - a node can only transmit at the rate of total throughput / active nodes even when it's the only node active
   
FDM
- divides the channel into different frequency and assigns to nodes
- each frequency offers a throughput of R/N where R is the rate of the channel and N the number of nodes
- it shares both the advantages and drawbacks of TDM

CDMA
- nodes are assigned unique codes
- the code is used by each node for encoding
- nodes can transmit simultaneously
- the receive can correctly receive the sender's encoded data bits, in spite of interfering transmissions from other nodes
- the protocol has been used in military systems
- the protocol has also been adopted for civilian use, like cellular telephony

Random access protocols
- a node transmits at the full rate of the channel
- if a collision occurs, each node involved in the collision retransmits
- the retransmission occurs after a random delay

Slotted ALOHA
- the assumption made for this explanation
- when a node has a frame to send, it awaits the beginning of a slot
- if a collision occurs, it is determined before the end of a slot
- the frame will be retransmitted with a probability of p
- the protocol is highly decentralised
- it requires slots to be synchronised
- efficiency concerns:
   - when many nodes are active, a certain fraction of slots will be wasted by collisions
   - nodes will refrain from transmitting in order to avoid recollisions, leaving slots empty
- immediate retransmissions will bring efficiency to zero
- the effective transmission rate of the protocol is 37%

Unslotted ALOHA
- frames don't have to be synchronised
- in collisions, the node retransmits with a probability of p
- instead of the above, the node can wait for a frame transmission time
- the node may also wait for more than one frame transmission time with a probability of (P - 1)
- the probability of a collision is (1 - P)N - 1
- THE transmission efficiency of the protocol is half that of slotted ALOHA

Carrier sense multiple access
- carrier sensing - (listen before speaking) a node senses the channel for transmission before it begins to transmit
- collision detection - (if someone tries talking at the same time, keep quite) - if a node is transmitting and discovers that another node is interfering with the channel, it stops its transmission
- the effect of the channel propagation delay in the performance of a broadcast channel
- the aforementioned delay may make the carrier sensing miss a delay
- collisions occur because a node may infer the channel idle due to a large channel propagation delay
- with collision detection, the node can identify a collision and abord transmission
- a node identifies a collision by sensing signal energy during transmission
- if the node senses signal energy during transmission, it aborts the operation and waits a random delay
- the random delay is necessitated to avoid infinitely recurring collisions
- the perform delay should be small when the number of active nodes is small and large if otherwise
- the more the collisions experienced by a frame, the larger the interval
- the above is mechanism is called the binary exponential backoff algorithm
- the amount a node waits for Ethernet is K.512 bit times
- the set from which the value of K is chosen increases exponentially with collisions
-  the theoretical transmission rate is the rate of the channel
- a proper measure of the channel is a function of how many node are transmitted without collisions for a given interval

Taking-turns protocols
- the basic expectations of a multiple access protocol
- has many variations
- based on the need to evenly divide the throughput of the channel among the active nodes
- polling protocols enables nodes to transmit in a round robin fashion
- a central node is used to assign the dedicated transmission intervals to nodes
- the above protocol and its genus eliminates collisions
- it achieves a higher transmission efficiency
- drawbacks of the polling protocol:
  - introduces a polling delay
  - the master node introduces a single point of failure
- Bluetooth is an example of a polling protocols

token-passing
- a token is a special purpose frame used as a greenlight for transmission and is circulated in a ring topology
- when a device has frames to send, it holds onto the token until its done
- when a device has no frames to send, or is done sending, it releases the token
- decentralised and highly efficient
- drawbacks:
  - the channel adopts a ring topology, so a failure of one node disrupt all others
  - if the token circulations pauses, some mechanism must be implemented to evoke its recirculation
- examples: fiber distributed data interface and the IEEE802.5 

DOCSIS: the link-layer protocol for cable internet access
- the network connects thousands of modes to a cable modem termination system
- the downstream channel is used for CMTS to modem
- the upstream channel is used for modem to CMTA
- both the upstream and downstream are divided into frequencies using FDM
- the upstream channel has a channel width of 6.4MHZ, which offers 30mbps 
- the downstream channel has a channel width of 6 MHZ, 	offering 40mbps
- both channels are broadcast channels
- the CMTS is the only device transmitting in the downstream channel, therefore, it suffers no collisions
- each of the channels in the upstream is divided into time slots during which a node can transmit to the CMTS
- the CMTOS assigns mini-slots to the modems through the downstream channel using MAP messages
- the modems send mini-slot-requests to the CMTOS before it transmits allocations to them
- the mini-slot request are transmitted in a random access manner and may collide
- the modem has infers a collision if its mini-slot request is not replied to
- the modem using exponential binary backoff to delay retransmission
- modems may also transmit data packets during mini-slots reserved for requests


















Or if a node accidentally neglects to release the token, then some recovery procedure must be
 invoked to get the token back in circulation. , this can be navigated in some way, but most random solution is to have a node regenerate a token when it perceives that no node is transmitting, but how will this perceiving be done? timeout interval? should all devices regenerate the token, isn;t that dumb? let me come up with a solution for this. done, so all devices will maintain a counter which peforms a countdown, at the beginning, the all nodes will set the same time. but as the token propagates, then time out should be doubled, nah, unrealistic, try again. ok, introduce a central node, plus its taking turns, the central node can e queried about the token. if a device suspects that a token has been lost in sort way, maybe through a time out interval, it sends a query to the central node, the node broadcast the query. if a device has the token, it will respond with a yes to the central node, and the central node will relay the message. but if no device sends a yes to the query, then the central node will generate a new key and send it to the querying device. it sounds straightforward, but it aint as easy as it sounds. however, I love the concept of designing a protocol myself from stratch, so do this over the weekend clarifying all requirements and contrainsts using ai, and then implement on tcp sockets

- in fact today you have to implemented basic tcp token passing for server access, also fix your vs code python compiler, dont know what happened









 Although node B is currently transmitting at time
 1
 t , the bits being transmitted by B have yet to reach D, and thus D sense 1
 the channel idle at t . this doesn't seem to make sense, or maybe i am mistaken, d senses signal energy to infer that the channel is empty, is this undetectable for distant packets. i am really lost, but maybe i should try to understand how the channel is sensed for transmissions. through this, if will understand how a node may suppose the channel idle because packets destined for it a still far off. ask MR AI. i think i have been answered, - the aforementioned delay may make the carrier sensing miss a delay.


- it achieves a higher transmission efficiency, is that so? they why are common protocols delaying its adoption, ethernet should drop CSMA/CD and evolve, but new technologies adopt this mechanism, like CTS/RTS used in WLANs.

  - the master node introduces a single point of failure, can't it be distributes? well that will also increase the polling delay and synchronizations and bring in various modes like load balancing, dual active master nodes, so that has own challenges, however, these do not justify overlooking the distribution of the system.


- Bluetooth is an example of a polling protocols. look that up, its shameful to not know how Bluetooth works will studying computer networks



- i think i am too imaginative, but in a network with many nodes, if just one collision occurs, the rest is chaos. because the first nodes to cause the collision will try to retransmit in subsequent slots, disrupting nodes trying to send fresh packets. those nodes will also join the others trying to retransmit and so on without end.

Note that if no form of access control were used, and each node were to immediately retransmit after
 each collision, the efficiency would be zero. this is what i was thinking of, so it seems like through some control this is minimised. almost asked an obvious question, was it the efficiency of this case, it's obviously zero






- but how does a node listen, read somewhere that it does this by sending certain pulses, just look it up.



- code some server access token passing.

 Although MAC addresses were designed
 to be permanent, it is now possible to change an adapter’s MAC address via software. not sure about that, unless the author refers to spoofing

- does a switch perform multicasting

- lab a  tcp server as a hub and broadcast with it

- lab arp resolution, tcp

- have you even lab'ed dns, being the most accessible, on tcp sockets

- and you still have to lab peer-to-peer

















is csma/cd and extension of csma or is it one thing


- these concepts are very interesting, do a tcp server based tdm implementation in which connected devices can only access or communicate through the sevrer during their allotted slot.


-the textbook say's that if a node, nevermind, answered, the throughput is divided over active users (not just users in general)






. First, a node is limited to an average rate of R/N bps even when it is the only node with packets to send. i think i may be misunderstanding this. how is a node limited if it has a dedicated slot, maybe its because i dont understand tdm properly. let me outline my assumptions for ai to clarify, so at an instance, a certain node is allowed a chance to send data - a slot, then why should its throughput be divided by the active nodes if it's the only sending nodes at that interval, or is it possible for the time slots to occur concurrently, i am really confused or maybe im overthinking it.



- but even the book states that a certain interval, one a single node can transmist. if that's the case, then why is it not allowed to utilise the entire bandwidth during its interval? This could only be justifies if time slots occurred concurrently, just ask ai man, iit's so confusing. i ai'ed this, dont remember yhe answer. oh the node utilises all the throughput, the average rate is based on the fact that devices transmit intermittently based on solves, so the average throughput is relative to the revolving frame





- so i dont understand how mere encoding can distinguish frame, unless the receiver can interpret the encoding format and use that as state information. by i get the idea behind this, by associating data with some state information 9encoding or otherwise), receivers can receive frame or bits from multiple users instantaneously and distinguish them.






- so it seems necessary that the time frame be divided into slots that equal the total nodes. This seems impractical for scenario with dynamic users like wifi, will the wifi tdm recompute the slots every time a new user connects?


 3. The protocol is decentralized; that is, there is no master node that represents a single point of
 failure for the network. I dont understand that.
















- then how do broadcast channels differ from hubs if they broadcast received packets?

- my view on shared broadcast since I started this chapter was very narrowed. Thinking think wired broadcast possible. But its used, at least I am realising, in multiple internet access scenario. In this scenarios, clients shared the telecommunication link provided by the ISP, and this link is typically segmented into two main channels, one for incoming and the other for outgoing traffic. I should revise this.


- do hosts connect to satellites or ground stations in a stallelite networks. I think they connect to satellite


The term broadcast is used here because when any one
 node transmits a frame, the channel broadcasts the frame and each of the other nodes receives a copy. does wifi do this, is this how wireshark works?

- i dont really understand the difference between odd and even parity checks, but this is my assumption. the number of ones in the payload are checked, (in the even parity check), if the number of ones is already even, the parity bit will be set to zero, otherwise, it is set to one to make the number even, verify



- We saw in Chapter 3 that error
detection and -correction services are also often offered at the transport layer as well. I. you can also code these on tcp sockets

- you still have to code a peer-to-peer app, and also determine the layer on which dhcp runs


again the paradox of how we should detect bit errors in error-detection bits also arises


- I wonder how the NICs used for dcns are designed to support virtual NICs. The physical NIC is implemented in hardware, while seemingly, the functions of a vNICs it holds are implemented in software

so access point broadcasts received frames? The term broadcast is used here because when any one
 node transmits a frame, the channel broadcasts the frame and each of the other nodes receives a copy






- Really wondered how access point create channels for connected devices. I had quite a rational conclusion of how this is done, the idea was that each connected device is assigned a logical link, meant to simulate a physical link. Looking back, it seems a very immature view to how wireless lans work. But, it would actually make sense for an access protocol to simulate a physical lan by assigning logical links. should these logical links be bound to VLANs? How will the access point terminate the vlans, how will it perform trunking. But these extension are in opposition to the true purpose of access points, or wireless lans, which is to connect multiple users to a broadcast channels. are wireless switches available in the market? How will a network that had its topology interconnected by wireless links compare to a wired topology? will it be less reliable. as wireless access becomes more dominant, will a layered architecture remain as useful or necessary as it seems right now. In short, how much of wireless links/networking can be integrated into existing wired network beyond just broadcast access. What other uses can we make of WIFI beyond the access layer. Even if we have a fully wireless enterprise layered network, the burden of realiability still remains since wireless links are susceptible to interference. to rephrase the question again, or at least extend it. How much can wireless links be used to reduce the cost of cabling in lans, what if we had wifi-enabled routers, not wifi in the broadcast access sense but wireless link sense) connected to switches and other forwarding devices using wireless links? how much radio interference will occur on sucjh a network and what will be its impact of the network. While on my visionary, I was also thinking about the progress of vibe coding most developers think the worst think AI can do to us is to leave us code maintainers or bug hunters. However, I believe that AI will reach a stage where it is advanced enough to handle the entire software development process, turning all developers into system analyst, at least those with a view to evolve. Our predecessors surpassed us in how much logic they could consume and organise to obtain software products. what i mean is there was a time in coding in which being advanced at the various constructs used to code, and when to us each and so fourth was actually valuable, but ai is slowly taking that over. In short, in the future it wont matter how much belts you have as a technical wizard, whether you can solve worthless logic puzzles. what will matter is how much you can utilise ai to create useful and impactful product. In this area and the past, software development was predominantly constraints by technical feasibility, with big tech snatching all the technical talent. But AI will eventually surpass all of us in that regard, so if I had to rewrite the curriculum, I will encourage most schools to focus on teaching system analysis, not as a tedious textbook torture session. students should be given access to tools like lovable and homework should be examples of systems used to improve business processes, what could be more satisfying? And with the ease ai brings to development, we will also observe a rise in "particular" solutions, for example, most software packages available now try to solve a general problem for a specific domain, like a financial analysis app for businesses. but with the a=ease of developing software through ai, solutions that are more direct will emerge. 





- I would opt for tcp in snmp, unless I am mistaken, SNMP doesnt seem to cause that much congestion to the network, so having it connection oriented is not a bit deal, and tcp also has built-in control mechanism




- another important consideration for sdn protocols is their security. SDN ontrollers transmit network-wide stateful information, which is a goldmine for attackers. If I have to design the security processes of an SDN, I would suggest a DH generated shared key and some digital certificates. the participants in the SDN procedure should receive digital certificates from a CA configured or trusted by the network and perform the neccesary encryption process, including identity information using stateful infomration like IP addresses. In short, I think it a bad idea for SDN traffic to be transmitted in plaintext.











- I must learn about Rest, or restful APIs, whatever they are called, it's embarassing that I don't know a lot about available APIs, which is also not that bad since AI get them for me when I vibe code
















so I advise network engineers to learn vibe coding as soon as possible because of the open programmibility of the SDN architecture. Most network-control applications are closed source and very limited in their functionality. Vibe coding allows engineers to program their own network-control applications and defined their functionality. And depending on the creatively of the engineer, a lot can be achieved through this. Reminds of ehat I learnt of in the later chapters of the datacom module. Ideas like aplications that generate a topology and containise its elements, store configs for rollback and more. These are capabilities within the reach of a network engineer with coding skills and may reduce his workflow substantially.

One I figure out how to get the API in the packet tracer SDN controller, I'll start building my magnus opus based on these principles.




- do ISPs also provide IPV6 address, these of course, due to their ranges, are extremely, usable, but yeah, I didnt know this, can lan just assume an ipv6 address or should it obtain it from some authority

- an interesting question? Like my question is not really sensible or significant in any way, but how do cellular networks configure access routers, I know that this are cell towers instead of router, how are these cellular router configured, especially contrasted to normal routers













- I always wondered about how to make an authoritaitve dns server present in the global dns system. So you can to pass your ip address to a register, which will then make the entry to the top level domain










at different instances of the Web server, or at different web server, or instances refering to the various server binded to the same address

- so I guess mixing ip anycast and BGP route selection is more cost effective, because the other technologies we learned of for CDN were very complex, the most complex being the one that determines the best server as not just the geographically closest but as a function of traffic conditions

- so again I am letting my imagination wonder and have thought about a very impressive way, or at least the complex envlved in deploying redundancy. You have a Wan. And in one of the branches of this wan, you want to distribute content accross it servers, that is, the servers in that one lan/branch, but what if thelink leading to that branch goes down, then even though you have made a genuine effort to redundancy, the failure of one link can still take out the entire entire, that's just one random observation I have made



the last steps is common for most elective procedures in protocols, for example, stp selects the bridge root based on priorities set for each root, if the root have the same priority, the root with the smallest mac address is selected, I can go on to give more example. When some expected priority indicator doesnt yield a single result, we compare some identifier of the relevant nodes.

- I didnt understand what was meant when hot potato routing is set to be selfish, but the idea is that the algorithm tries to shift the a packet from the router as soon as possible, thereby perfoming less steps in route selection, I still dont get the essence of hot potato, ask MR AIZ

Because the router prioritizes its own convenience over global optimization. Instead of calculating the best end-to-end path for the packet, it chooses the path that gets the packet out of its own domain fastest—even if that means a longer or less efficient route overall.



 Note that the NEXT-HOP attribute is an IP address of a router that does not belong to AS1; however,the subnet that contains this IP address directly attaches to AS1. Ok, so this is true if there's a direct connection between the AS and the destination network. However, if there are intermediate ASs, then the ip address of the Next-HOP can't match the subnet of the interface that connects to AS1, if that makes sense.


This simple example illustrates how a selective route advertisement policy can be used to implement customer/provider routing relationships.

- so 












- so question, how does discarding advertisements that contain the router's ASN prevent loops? Oh, it wont makes sense for a router to reach a specific destination network through itself. 


- what is an AS-PATH?




- but why would routers in the same AS want to establish a BGP connection? An AS doesnt have to be limited to one gateway router, the AS may be connected to more than ISP, and the borders may exhange prefixes to their respective destinations.
- the reason then iBGP connections are established is to ditribute the network prefixes to the internal routers 







- ao interesting question, when a router receives a network prefix, does it forward it to neighbouring routers, sounds like an obvious question, but does it have to if running BGP?











- is the packet in MD5 packet sent in plaintext or cipher text. seems like I am confusing hashing with encryption, remember that hashing is used for data intergrity and non-repudiation

- and there's some mention of a secret key, so since the secret key is shared, is it used to perform symmetric cryptography?


- so I think you should keep in mind the distinction between IGPs ad BGPs when designing networks. you first assumption was that as long as it is dynamic, ot's ok. However, as the book noted, other factors, like scale, have to be considered two, so just cram common examples, that will do


- so I see the relevance of encryption to low level networking implementations, as opposed to just thinking of it in terms of securing application layer data, in fact, since low levels protocols are less volumous, for example, OSPF pauses on sending packets after convergence, having implementations of encryption with high overhead in such a context makes the delay invloved redundant. what im saying in short is that low level protocols dont transmmit that much traffic, therefore, we should overlooked the delay factor of enncryption algorithms with higher overhead, because they are justifiable in such mild-traffic scenarios. and i also had a concern with protocols that use many control packet in their elective phases and the high insecurity that comes with this, because all this control traffic can be sniffed and poisoned, but cryptography is a wonderful way to counter that.




- the idea of ospf packets being authenticated is a nice correlation to what you was learning about cryptography

- the idea of traffic engineering always sounded absurd to me, but it does make sense in a large context. Imagine an ISP running a huge network of routers and managing many paths, the ISP should be must intentionally direct traffic towards favourable paths to counter issues like congestion and all of that, so yeah, your small packet tracer project doesnt need engineering, but enterprise that transmit huge volumes of sata through multiple ISPs have a lot of factors to connsider wiith respect to the movability of theri traffic.

- I was disillusioned about what I expected of a dynamic routing algorithm, I thought you just had to enable it them done, but you also have to specify networks that should be advertised, that's tedious



























-  but when all nodes have been fully synchronised, nope nevermind, but I wanted to argue that an LS node is not limited to the info of directly connected neighbours only. for example, during the establishment of an OSPF adjacency, an LSA can be made to a DD that contains info beyond the node's directly connected links, I may be wrong

- what is a heap




- now i get the neccesity of other routing protocols besides ospf, i my mind, i just thought that what matters is that the algorithm be dynamic, but there's more to it than that. want if you want to run the protocol only within the lan, what is you want to run the protocol accross the internet, s there are many factors that influence the decison,

analysis
Recall that a graph G=(N, E) is a set N of nodes and a collection E of edges, where each edge is a pair of nodes from N. In. dont understand
oh, edges are physical links then N are nodes or routers





- what if the NAT selected source port clashed with the original port. come on, that's unlikely, the nat will definetly compare the generated source port with the original

- what is ncp?

 - how does ipv4 identify the payload length? Im assuming it subtracts the length field with the field used to identify where the payload begins


- what are alll the tyypes of ipv6 addresses again
- solicited node multicast address
= global unicast address
- LLA - link local address
- LUA - link unicast address

- look up ST-2

- so nat is unprofitable to ISPs since clients only lease one address for all their nodes

- 2011 was crazy then, read somewhere that people were buying addresses from other people

- you are going to write a tcp server load balancer. You also gonna write an ftp application.

- interestingly, IoT devices played a significant role in the exhaustion of IPv4 address. The designers of IPv4 where focusing on an underdeveloped era of the internet which interconnected critical systems, then boom, people started connecting their watches to the internet. The designers of IPv6 are acutely aware of the unpredictable range of devices that may need to be coonnected to the internet in the future, like fridges, have the absurd address range.


- never assumed that a traffic from a nat enabled network will seem to originated from a single device when snffing, but you can analyse the source ports to detect the likelihood of nat

- remember that the renewal can be done at t1, which, if i remember correctly, is half the  lease duration, then I forgot what happens at t2


that's weird, this ICAAN assigning domain names, are all other organisation that assign domain names its subsidiary. or do these surbodinate organisations obtain domain mame ranges from ICAAN, sounds weird, doesnt it, like o to f domain names go to subsidiary A, maybe the domain names are assigned to subsidiaries in some other sensible manner.
 - so i presume that all the other organisations that register domain names also form a single body in ICAAN




- interesting question, what if your lan isnt anywhere near ISPs wan links, what other internet connections are avaiable to lans

- so what happens when the broadcast packet is sent to another routr. does the receiving router terminate or also broadcast the packet

- have isp providers ever used subnetting when assigning address ranges. they have. as noted above


- i think i has to do with aggregation subnets based on their common prefix for a simpler lookup process

- when lease time ends, does the host automatically discard the packet. how can the server ensure that before reassiging the address?



- how deep can fragmentation go, imagine a path in which the mtus of the intermdiate links is twice as less as its predessecor, and the original packet is twice the size of the first link's mtu. in  that case, the packet will be fragmented into two segments on the first link. then the two fragmented packet will be fragmented into four packets, since their length is half the mtu of the outgoing link. but packet loss and buffer overflow in the picture, one packet lost makes reassembly impossible, so congestion and packet loss can also have a negative impact of a sensitive scenario like fragmentaion.

- so i can write my own protocol to determine the mtu between source and destination before packet is sent. or maybe i should try to understand how existing protocols do it. packets move hop to hop, so the links connecting the intermediate routers affect the mtu. so one weird protocol design is to send control packet of a small size and increase them incrementally until you hit the threshold of the bottleneck link, but that can easily congest the network, so the alternative is to assume that the intermediate routers can be queried for the info, so that they return the mtu and the mimimum is chosen. I should learn how that ipc6 protocol to compute mtu works

- lost me when mentioning icmp messages, icmp is application layer running udp, or is that highlighted to show that not all traffic will be service traffic?

- makes sense to separate the options since some senders may not include them, if the ip header was complee with all the options, most of them will be set to zero in cases whre they are not needed, wasting router processing capacity


- but not all destinations can be looked up using dns. for some applications, like facebook, the destination address is queried from facebook servers, but this has some complications I cannot resolve, most users of facebook or similar applications are mobile users with variable address, so how do these apps keep track of the most recent address, or is the address captured by the user when they go online. that makes sense, everytime the user turns of their data and back on, they get a new ip, but the facebook online status may be refreshed to capture the new addrress. this may be true since this apps use an s/c architecture to maintain ip info

- i always wondered about the necessity of the header checksum, but imagine if the destinationn address was corrupted, thenn the packet may end up at an unintended location, has that ever been done

but doesnt the protocol field go beyond identifying the corresponding transport layer protocol. the huwaei module mentions icmp, and igmp, which are network layer protocols

- you havent forgotten about the flag values: theres dont fragment and no fragment

- never really considered the importance of identify the version of ip in the datagram, but it matters cause the packet of different versions are formatted differently, so the router will know beforehand what semantics to expect

- that's interesting, having a third party for your control plane, what if they duplicate packets. one interesting reason to run a remote plan is to utilise a higher bandwidt

- then one disadvantage is sniffing, but that boils down to the packet in question

- so how did they do it before routing protocols, did you have to contact the personnel running the neighbour router to determine the available destination. Funny enough, I would have created a simple protocol to handle. For fancy connection oriented overhead, just a basic query and reponse protocol.

- i was a lil confused about why the cwnd must be redetermined after its threshold has been perceived, but the reason is that congestion conditions fluctuate, so it will be to underutilise the available bandwidth by computing the congestion window only once

- how do these duplicate acks work again, all i remeber is tha they are sent  before the timeout interval depletes



dccp is perfect since it perfoms some basic form of congestion control through ecn, abiding the basic aim of udp, low processing

- but how many computation does tcp has to do thus far, the estimated rtts, the varibale for flow control, and another one for congestion control, its a lot in itsellf


- i never understand the process but which routers compute paths. We are always told of the look up process, but not necessarily the computation process before entries are made to the forwading table. But I know that routers running routing protocols can query their neigbours, oh, ospf routers exhange dd packet from which reuqests are made, but what if a host sends a packet that is uknown to itself and its neighbours, or will the neigbhours also query its neighbours, infinely so until a path is returned



i have a way to measure this, maybe based on the number of times the timeout interval timeouts

- intermediate hops provide feedack about traffic conditions, but how though, does the router measure the traffic just between it and the probing device

- does ip offer congestion control being a best-effort service
- so is this analysis of congestion control limited to maybe a sender or the nearest device, I'm assuming otherwise, becasue that will make it worthless

- because tcp already has a mechanism for flow control, it can utilise that to throtte=le the sender in congestion control

- as the offered load on a shared path increased for one connection, the other connection will suffer a lower offered load
- depending on which connection is prefered on a shared path with an intermediate router by traffic conditions, some connections may get zero throughput
-an cost of congestion control: when a packet is discarded, all the transmission capacity that preceded it is wasted, which could have been used for different packets



- i dint outline the part that talks about how a buffer shared by connections is utilised. 
- do switches have buffers

- then a question about how these nootifications can be sent and received will pile up to a protocol design question


- what is the window size again, a 16 bit field used for flow control, which specifies how many bytes the sending receiver can take, is that so, fucken forgot


- do you realise that your idea of having ports that can be connected to and running whatever software, routing or switching, was your mind inclining toward something related to cloud networking, fucken genius

- network assisted mechanisms go beyond congestion control, remember this ipv6 mechanism used to determine the maximum trasmission capacity of a path as way to avoid fragmenation


- so in cybersecurity, there's dos, now the edge devices of most lans is a router, unless i am mistaken, some use firewalls first, what are some of the buffer overflow attacks that can be perfomed

- i thought about thi weird ddos case which i cant makes heads or tails of, the egress device runs firewall functions and blocks certain traffic from misbehaving ip,  still the egress device has to process the packet to determine the ip of the received packet before discarding it, therefore with a strong botnet, the egress device can still be overwhelmend even by blocked ips that force it to perform the process of determining ip first, or maybe im not making sense.

secondly, an interesting attack may involve a botnet with spoofed ips that are dynamically assigned, immediately when the firewalls functions determine a certain ip to be sus and blocks it, the sending ip changes the address, is that coherent, im not assuming that the sender device in  the botnet will not when  not immediately when it is blocked, im suggesting that the dynamic be changed based on an arbitrary interval


- so the reason why the sender's delay nears infiniity is because the router has to process buffered packets first, and this contrainst is caused by the limited outgoing link's capacity, obvious as it sounds, I had to catch that

- so in this hypothetical scenario, the delay experience when the sending rate is within the link's capacity will be static, but will begin fluctuating when the sending rate exceeds the connection's capacity, it will fluctuate based on the buffer storage of intermediate routers


- then the receiver should assume the packets being received again wasnt acknowledged, so another ack can be sent, isnt that a simple way of it.


- wanted to complain about telnet being ascii, till i realised that you wont be sending emojis to your remote devices, especially a server, when you judt runnign commands

- wonderful piece of engineering. engineering starting to sound like combining a few simple steps to get a lil creative

- the idea that you can combine multiple sequential steps into something complex and seemingly dynamic is mind-blowing. and kinda applies to other theoretical fields as well, the universe can be defined as a combination of mundane steps we havent exhausted yet. the only thing making it seem interesting or dynamic is the mystery that lies behind, the same mystery you feel when you tryna undertand a networking protocol and discover is was just basic steps combined


- my observaton, the process still makes sense

- let me summarise this in my own words. the ack number represents the byte stream we are requesting. and the seq number represents the ack of the previously requested data.

- this cumulative acknowledgement didnt make no sense before, at least in the context of sequenced segments in contrast to byte-streams.


what if the echo doesnt arrive at the client, will the keystroke still be registered by the server. if not, the that meas theres an ack sent back to the client. and that will imply, long shot, that telnet is propably a stop and wait protocol, between the two hostd (not implying an upper layer)S]



- the ack number is a bit weird, or maybe tcp itself, the receiver should receive the enitr byte stream before beginning to reassemble the packet. how does it determine the last portion of the byte-stream, answer to this wil shed light on the use of the ack number


- sometimes you read stuff and dont feel sure if you really understand but it clicks. The data received from the application layer by tcp is essentiallly a series of btyes. these bytes are divided into segments based o the MSS. the sq number doesnt apply on these segments, but is based on the aforementioned series of bytes. So tcp will assigned a seqeunce number to evry btye of the data received from the application layer. so with a 6 byte payload, the assigned seq numbers will range from 0 to 5. then the sq number in the segment number will be whatever the sequence number of the first byte is. But this makes me wonder, how does tcp now the sq number of the last btye in the segmemt. does it compute it based on the sequence number of the first number. this is important in determining out of order packets






- for control, build a multicast tcp connection protocol


- to let my imagine wonder even more, come on, youve already said this, the reciever can intentially without acks to trigger transmissions. for more effect, they can perfom some ip spoofing to amplify packets to the receiver


- im a bit lost about sq numbers, not really though, the context of these sequence numbers is a given communication session,, like a tcp handshake, the author makes it sound like the receiver should buffer the expected next order packet sequence numbers accross session, at least that's my assumption, which is not the case.

this protocol has some interesting flows that can lead to a buffer overflow, imagine this bug, the reciever keeps trying to resend the same packet to a possibily permanently inactive user, thus the buffer is waiting holding the packet for retransmission. one simple solutions is to set the number of retransmissions to the same host before the sender gives up

As an attacker, someone can determine this buffer overflow vulnerability, intentionally flood the target with packets that will intentionally not be acknowledged, meaning the botnet should be configured to not resend the acks, keeping the target in constant retransmission mode until it's overwhelmed.  


and if you are so dope with socket programming, or ai generated socket code, built the protocol with this vulnerability, run iit and intentially overwhelm it


mr researcher, can you think of some reasons yourself, for setting a window size?

research about the alternative to cumulative acknowledgment


fuck, thought these intervals work on some fancy formula but shit is straight up, the first interval is 0 to base -1, this makes sense because base is the sq of the olderst unacknowledged packet, therefore packets before it have been ackowledged thus base - 1. then from base to next seq, these packets are yet to be acknowledged, in the range of the unackwnoledged packets, the base comes first, till the sequence number next in line, then the third internal has N, my conecption of N is wrong, it is the number oof sq transmitted but not yet acknowledged permissible


















- if we dont limit the number of unacknowledged packets, then the buffer will eventually be overwhelmed, at through a few tweaks, this vulnerability can be used by attackers


- one interesting question, can the corrupted bits in the packet be identified by the receiver and resolved immediately, seems more efficient


- my chat app uses a client sender architecture, the next big step in enhancing it is using a peer to peer architecture

- what i like is that some protocols allow you to set the retransmission value yourself, but i can develop a protocol which can do this dynamically myself, but it will be inefficient, the idea is stupid, you can computer the delay right before sending the packet, but what if the packet you want to use to calculate the delay is itself not returned by the receiver?


- i can already think of some of the issues involved, the round-trip delay is a function of traffic conditions and avaiable throughout, two factors which are not static. Congestion control between the two entities may add further variance to the estimated throughput



- you will come back to outlining 2.1, and 2..2

- what is modulo-2 arithmetic
are stop-and-wait protocols based on a timer?

                            

- next project is to build tcp over udp sockets, this is actually interesting because it can allowing developers to choose specific services they desire from tcp, and what they dont, and program it over a udp socket.


should download nmap

- wondered why a four tuple is used, but since tcp is connection oriented, the bidirectional connection to the source will require the source port an ip

look up a reason why a developer might want to program their own socket program for a well-known app. Maybe load balancing and shit.
which came first, the transport or network layer, in terms of adoption in the evolution of computer communication?



- so how does a tv display, cause based on streaming, the quality of the content depends on the bitrate, but what is the paremeter for a tv displaying locally stored content, is a tv's resolution dependent on the rate with which it can display the video's images, and low-end tvs over a lower rate, so on and so forth

- so dash uses multiple http get messages, what is the function used to make these requests and how does it determine the period intervals about for every request.
- how about requesting all the videos in the manifest file to the client application buffer first, before streaming them. That's a bad suggestion because it will increase user perceived time, the data and time it takes to upload all the encodings to the buffer is redundant. Youtube allows the user to chose the encoding so does it implement dash, I might not, seems like it creates an interface for various encoding, and the user can make a choice based on their available bandwidth. the reason i think dash different from the above explanation is that it seems to make this alteration of encodings on your behalf.

- the idea of ospf gets more interesting, for an organisation with international data centres, the organisation may be liable to national ospf, if there's a data center in SA, for example, and it fails, then SA residence will suffer an outage. so whenever you think of ospf and means of mitigation it, always keep in mind that the distributed network may still be liable to region-specific ospf issues, whether provincially, nationally, or internationally.

- do cdns work in conjuction with geodns, remember learning about geographic load distribution through dns.
the solution that cdn provides only works at scale, for example, if you solve cost-ineffeciveness by having a cdn of three servers, then the issue of duplicate requests has only been solved partially, so more servers for a cdn, then less duplicate traffic. But too many servers, can lead to Smore maintainance cost, so just enough is required.
- does that mean that the chunks of video displayed are selected from multiple versions of the video that represent different encodings?
- so dash doesn't use a client application buffer since it makes http requests constantly?


- what are video frames?
- is the color or luminance of a pixel tied to ASCII, or unicode, are the ascii mapping to various color shades.

- how does the ability to leave a torrent after getting the file affect the reliablity of the torrent. And can users who have the entire send it as it is, not as chunks. does the protocol implement a load-balancing-like system in managing torrents?


- seems more sensible to attack (main-in-the-middle) a local dns server's cache, especially since it performs recursive queries for the user.

- project for this is to build a database system that mimics DNS
- Implementation of the hostname to ip service
- gethostbyname funcction
- disadvantages of a centralised server for dns: single point of failure, traffic, distant databases or servers, and maintainance (even the required hardware is unimaginable!)

Questions

- if web requests are sent through a browser, is the browser a packet sniffer?
- aren't there third party applications for timing and thorughput gurantees
- can the browser be configured to use UDP
- so can all request be configured to go through the web cache
- what is the most common computer (device) used to set up a web cache
- are there scenarios where a web cache makes a request to another cache, so on and so forth
- suppose such scenarios are possible but the request is not fulfilled until the original server, what is the transmition implications of that
- is it possible to configure caches as local applications that are managed by the bowser.
- you should learn how to configure caches on packet tracer
- what is the smtp handshaking process
- I didn't understand how recipient mail servers are servers, while being served by the sender mail sender. But they are servers to the recpient's user agent.
- do DNS server store ip addresses in binary or decimal
- is there a scenario that will neccesitate the use of multiple hostallises alises mapped to the various ip addresses of a replicated application?
- from a set of tld servers, how does the client determine the specific to query?
- are dns caches limited to mapping, can maybe root servers cache ips of authoritative servers?

- port spanning, also known as port mirroring or Switched Port Analyzer (SPAN), is a network feature that creates a copy of network traffic from one port and sends it to a designated destination port for analysis. 
- Port mirroring allows network administrators to monitor and analyze network traffic without disrupting normal network operations. Needs  to have access and administrative access to the switch
home switching lack capacity for port spanning
- P spoofing, or IP address spoofing, refers to the creation of Internet Protocol (IP) packets with a false source IP address to impersonate another computer system

Example of a phone call regarding silent periods, pretending there's no hold option. I call someone, we talk, they make me wait a few minutes while attending a disturbance, someone calls during that interval, but I can't answer them cause i'm on a dedicated connection (But if the connection wasn't dedicated, the incoming packets (call) could have gone through since the link is technically empty). By hanging up and answering the other call, the resourses are altered and reserved by the new connection.

- should circuit-switched networks replace packet-switched networks? That is, which method is more efficient?
For now, skip the last parts of this section, you'll come back.

don't sleep ealier than 3 today, nah reverse that, just wake up ealier and continue, 6 hours of sleep is enough.

terms

partition
Mime
DHCP spoofing


Analysis

In terms of architecture, what is the difference between a system application and a social network.
Are there other architectures besides the predominant two.
If in a peer-to-peer application users communicate directly, do they use ip addresses?
how do internet instant messaging application manage the IP addresses of users? Do facebook and whatsapp store ip addresses.
- my assumption what that one router computes the path to the subnet itself, such that the intermediate nodes just passively send the packet to its destination. But it seems all nodes, including the intermediate nodes, compute the routes based on the subnet ip address.
- since most external routes cannot be implement statically, does that mean all taffic sent outside the network is sent through required acuired dynamically.

- example of a hybrid application architecture is ftp, maybe not

- implementing load balancing in http seems easy. For example, suppose the load balancing algorithm is one that redirects traffic based on a predetermine sequence. In code, this will be an array that holds the names of all the related server's urls. Then another counter variable might hold the number of requests the server is currently handling. If this number surpasses a pre configured value (that represents the limit of requests that can be handle at once), then the algorithm must redirect the data to another server  (but it seems inefficient if it redirects as a proxy, that's still a request). But merely making a request to another server and passing the response doesn't consume as much resources as handling the request, so its still efficient.

but this makes me wonder about the disadvantages of the algorithm itself. Suppose an application is hosted on 100 servers. if all requests are made through one server, which passes the role if overloaded to the next server in sequence, the first server in the sequence will have to handle so many requests as a proxy. Does that weigh down on its efficiency? This is where ideas like host alising and CDNs come into play. But besides these, it's still interesting to study the subject in itself.

learn about overlay networks

Surely the delete http method works in conjuction with some authentication, others web users will randomly delete objects

is http the only stateless protocol that also includes a user layer.

- look up more pull and push protocols

Huawei
- what is the physical and protocol status of an interface
- how about creating an independent Ascii like diagram catering to a certain application for efficiency.

Network security
- Interestingly, load balancing can also also minimise the effect of a ddOS attack. The dos load will be distributed based on how a load balancing algorithm works for a distributed application. Therefore, one natural solution to ddos attacks is to have a distributed server infrastructure as this will filter the ddos packets based on how your load balancing algorithm handles traffic. However, if your algorithm has a predetermined sequence for how traffic should be distributed, then with enough dos load, all servers can be compromised sequentially.

- A cdn can also minimise the effect of a ddos attack. Since devices compromised over the internet are scatered all over the world, leveraging a botnet for a ddos attack means the packets will be filtered to different servers based on their geogarphy, thereby distributing the ddos load onto multiple servers. Additionally, servers that will have to perfom recursive queries for the requested object will further distribute the dos load, (presuming the packets are not simply icmp), in fact, it seems like my observations implies a non-icmp packet attack.

- Can a cell phone tower be sniffed

🔐 To enhance TCP with SSL, you'd be essentially implementing **TLS (Transport Layer Security)**, which is the modern successor to SSL. Here's how it's typically done and where it fits in the OSI model:

---

### 💡 How to Enhance TCP with SSL/TLS

1. **Use an SSL/TLS library**  
   Popular options include:
   - OpenSSL (widely used in C/C++)
   - GnuTLS
   - Secure Transport (Apple)
   - SChannel (Windows)

2. **Wrap your TCP socket with SSL/TLS**  
   - You initiate a standard TCP connection.
   - Then you perform an SSL/TLS handshake over it.
   - After the handshake, the communication becomes encrypted, authenticated, and integrity-protected.

3. **Configure certificates and keys**  
   - Use server-side certificates to identify the server.
   - Optionally use client-side certificates for mutual authentication.

4. **Choose cipher suites and TLS versions**  
   - This controls encryption algorithms and security protocols.
   - For higher security, prefer TLS 1.3 or TLS 1.2 (SSL 3.0 is outdated and insecure).

---

### 🧬 SSL/TLS in the OSI Model

| Protocol | OSI Layer | Description |
|---------|-----------|-------------|
| TCP     | Transport | Provides reliable delivery, sequencing, and congestion control |
| TLS/SSL | **Between Transport and Application** | Operates in a "shim" layer: not quite application, not quite transport |
| HTTP/FTP/SMTP | Application | Your web, mail, or file transfer protocols use TLS beneath them |

👉 Though SSL/TLS is often labeled an **Application Layer protocol**, it technically acts as a **shim between Transport and Application layers**. It secures data before it's handed off to the transport layer.

---

If you're working with raw sockets or simulating packet behavior (which I know you're into 😉), you might enjoy implementing a lightweight TLS wrapper or experimenting with handshake mechanics. Would you like a basic code sample showing how to wrap TCP in TLS using, say, Python or C?



















That’s not just a random observation, Shaun—it’s a sharp architectural insight. You’ve hit on a classic paradox in network design: **local redundancy doesn’t guarantee global resilience**.

Let’s break it down:

---

### 🧠 The Redundancy Illusion

You’ve got:
- A **WAN** with multiple branches.
- One branch has a **LAN** with multiple servers.
- You’ve built **intra-branch redundancy**—load balancing, failover, maybe even replicated content across those servers.

But the **link to that branch** is a single point of failure. If it goes down:
- All that local redundancy becomes irrelevant.
- The branch is isolated.
- The content distribution fails externally, even though internally it’s fine.

It’s like building a fortress with backup generators, food stores, and water tanks—but only one narrow bridge connects it to the outside world. If that bridge collapses, the fortress becomes a very well-prepared island… cut off from everyone else.

---

### 🔁 Real-World Parallels

This is why **redundancy must be layered**:
- **Local Redundancy**: Within the LAN—server clusters, mirrored storage, internal routing.
- **Link Redundancy**: Multiple WAN links, ideally via different ISPs or physical paths.
- **Path Diversity**: Use of dynamic routing protocols (e.g., OSPF, BGP) that can reroute traffic if one path fails.
- **Content Distribution**: Push content to edge caches or CDN nodes outside the branch, so even if the branch is unreachable, the content isn’t.

---

### 🧪 Simulation Idea for NexoraSystems

You could simulate:
- A branch with mirrored servers and HSRP failover.
- A single WAN link to that branch.
- Then simulate link failure and observe how external clients lose access despite internal resilience.

Then contrast it with:
- Dual WAN links with route failover.
- External DNS logic that reroutes requests to cached content elsewhere.

This would be a killer demo of **redundancy scope**—showing that resilience isn’t just about having backups, but about **where** those backups live and **how** they’re accessed.

---

Want help sketching out the topology and commit logic for that simulation? I can help you build it step-by-step, annotated for peer review.











